{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Retail Sales Forecasting with OpenShift AI\n", "\n", "This notebook demonstrates how to build a retail sales forecasting model that can be deployed on OpenShift.\n", "\n", "## Project Overview\n", "- **Objective**: Predict daily sales for retail stores\n", "- **Data**: Synthetic retail sales data (2023)\n", "- **Approach**: Time series forecasting with feature engineering\n", "- **Deployment Target**: OpenShift with KServe"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["# Import libraries\n", "import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.ensemble import RandomForestRegressor\n", "from sklearn.metrics import mean_absolute_error\n", "from sklearn.preprocessing import OneHotEncoder\n", "from sklearn.compose import ColumnTransformer\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.impute import SimpleImputer\n", "import joblib\n", "import warnings\n", "warnings.filterwarnings('ignore')\n", "\n", "# Set random seed for reproducibility\n", "np.random.seed(42)"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["# Load the data\n", "df = pd.read_csv('../data/retail_sales.csv')\n", "df['date'] = pd.to_datetime(df['date'])\n", "df.head()"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["# Exploratory Data Analysis\n", "plt.figure(figsize=(15, 10))\n", "\n", "# Sales by category\n", "plt.subplot(2, 2, 1)\n", "sns.boxplot(data=df, x='product_category', y='sales')\n", "plt.title('Sales Distribution by Category')\n", "plt.xticks(rotation=45)\n", "\n", "# Sales by store\n", "plt.subplot(2, 2, 2)\n", "top_stores = df.groupby('store_id')['sales'].sum().nlargest(5).index\n", "sns.boxplot(data=df[df['store_id'].isin(top_stores)], x='store_id', y='sales')\n", "plt.title('Sales Distribution by Top Stores')\n", "plt.xticks(rotation=45)\n", "\n", "# Sales over time\n", "plt.subplot(2, 2, 3)\n", "df.groupby('date')['sales'].sum().plot()\n", "plt.title('Total Daily Sales')\n", "\n", "# Promotion impact\n", "plt.subplot(2, 2, 4)\n", "sns.boxplot(data=df, x='promotion', y='sales')\n", "plt.title('Sales with vs without Promotion')\n", "\n", "plt.tight_layout()\n", "plt.show()"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["# Feature Engineering\n", "def create_features(df):\n", "    # Create time-based features\n", "    df['day_of_week'] = df['date'].dt.dayofweek\n", "    df['day_of_month'] = df['date'].dt.day\n", "    df['day_of_year'] = df['date'].dt.dayofyear\n", "    df['week_of_year'] = df['date'].dt.isocalendar().week\n", "    df['month'] = df['date'].dt.month\n", "    df['quarter'] = df['date'].dt.quarter\n", "    df['year'] = df['date'].dt.year\n", "    \n", "    # Create lag features (previous day sales)\n", "    df = df.sort_values(['store_id', 'product_category', 'date'])\n", "    df['lag_1'] = df.groupby(['store_id', 'product_category'])['sales'].shift(1)\n", "    df['lag_7'] = df.groupby(['store_id', 'product_category'])['sales'].shift(7)\n", "    df['lag_30'] = df.groupby(['store_id', 'product_category'])['sales'].shift(30)\n", "    \n", "    # Rolling averages\n", "    df['rolling_7'] = df.groupby(['store_id', 'product_category'])['sales'].transform(\n", "        lambda x: x.rolling(7, min_periods=1).mean()\n", "    )\n", "    df['rolling_30'] = df.groupby(['store_id', 'product_category'])['sales'].transform(\n", "        lambda x: x.rolling(30, min_periods=1).mean()\n", "    )\n", "    \n", "    return df\n", "\n", "# Apply feature engineering\n", "df = create_features(df)\n", "df = df.dropna()  # Drop rows with NaN from lag features\n", "df.head()"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["# Prepare data for modeling\n", "# Define features and target\n", "X = df.drop(columns=['date', 'sales'])\n", "y = df['sales']\n", "\n", "# Split data into train and test sets\n", "X_train, X_test, y_train, y_test = train_test_split(\n", "    X, y, test_size=0.2, random_state=42, shuffle=False\n", ")\n", "\n", "# Define categorical and numerical features\n", "categorical_features = ['store_id', 'product_category', 'day_of_week', 'month', 'quarter']\n", "numerical_features = [\n", "    'promotion', 'holiday', 'day_of_month', 'day_of_year', \n", "    'week_of_year', 'year', 'lag_1', 'lag_7', 'lag_30', \n", "    'rolling_7', 'rolling_30'\n", "]\n", "\n", "# Create preprocessing pipelines\n", "numerical_transformer = SimpleImputer(strategy='constant', fill_value=0)\n", "\n", "categorical_transformer = Pipeline(steps=[\n", "    ('imputer', SimpleImputer(strategy='most_frequent')),\n", "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n", "])\n", "\n", "preprocessor = ColumnTransformer(\n", "    transformers=[\n", "        ('num', numerical_transformer, numerical_features),\n", "        ('cat', categorical_transformer, categorical_features)\n", "    ])\n", "\n", "# Print shapes\n", "print(f\"Training shape: {X_train.shape}\")\n", "print(f\"Test shape: {X_test.shape}\")"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": ["# Train model\n", "model = Pipeline(steps=[\n", "    ('preprocessor', preprocessor),\n", "    ('regressor', RandomForestRegressor(\n", "        n_estimators=100,\n", "        random_state=42,\n", "        n_jobs=-1\n", "    ))\n", "])\n", "\n", "# Fit the model\n", "model.fit(X_train, y_train)\n", "\n", "# Evaluate on test set\n", "y_pred = model.predict(X_test)\n", "mae = mean_absolute_error(y_test, y_pred)\n", "print(f\"Mean Absolute Error: {mae:.2f}\")\n", "\n", "# Feature importance (for numerical features)\n", "feature_names = (\n", "    numerical_features +\n", "    list(model.named_steps['preprocessor']\n", "         .named_transformers_['cat']\n", "         .named_steps['onehot']\n", "         .get_feature_names_out(categorical_features))\n", ")\n", "\n", "importances = model.named_steps['regressor'].feature_importances_\n", "feature_importance = pd.DataFrame({\n", "    'feature': feature_names,\n", "    'importance': importances\n", "}).sort_values('importance', ascending=False)\n", "\n", "plt.figure(figsize=(10, 8))\n", "sns.barplot(data=feature_importance.head(15), x='importance', y='feature')\n", "plt.title('Top 15 Feature Importances')\n", "plt.tight_layout()\n", "plt.show()"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": ["# Save model for deployment\n", "model_path = '../models/retail_sales_model.joblib'\n", "joblib.dump(model, model_path)\n", "print(f\"Model saved to {model_path}\")\n", "\n", "# Create sample input for testing\n", "sample_input = X_test.iloc[0:1].copy()\n", "sample_input.to_csv('../data/sample_input.csv', index=False)\n", "print(\"Sample input saved to ../data/sample_input.csv\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## OpenShift Deployment Preparation\n", "\n", "To deploy this model on OpenShift:\n", "\n", "1. **Create a Model Serving Image**:\n", "   - Use the saved model file (`retail_sales_model.joblib`)\n", "   - Create a Dockerfile with Python dependencies\n", "   - Build and push to an image registry\n", "\n", "2. **Deploy with KServe**:\n", "   - Create an InferenceService YAML\n", "   - Configure resources and auto-scaling\n", "   - Expose the service\n", "\n", "3. **Set up Monitoring**:\n", "   - Configure Prometheus metrics\n", "   - Create Grafana dashboards\n", "\n", "4. **Create CI/CD Pipeline**:\n", "   - Use OpenShift Pipelines (Tekton)\n", "   - Automate retraining and deployment\n", "\n", "The next steps would involve creating the necessary Kubernetes manifests and OpenShift resources to deploy this model as a scalable service."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.12.0"}}, "nbformat": 4, "nbformat_minor": 4}